{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复现课堂代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.539613Z",
     "start_time": "2019-06-30T23:40:19.031005Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import random\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.546543Z",
     "start_time": "2019-06-30T23:40:20.541556Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_grammar = \"\"\"\n",
    "sentence => noun_phrase verb_phrase\n",
    "noun_phrase => Article Adj* noun\n",
    "Adj* => null | Adj Adj*\n",
    "verb_phrase => verb noun_phrase\n",
    "Article =>  一个 | 这个\n",
    "noun =>   女人 |  篮球 | 桌子 | 小猫\n",
    "verb => 看着   |  坐在 |  听着 | 看见\n",
    "Adj =>  蓝色的 | 好看的 | 小小的\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.560543Z",
     "start_time": "2019-06-30T23:40:20.548538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsentence => noun_phrase verb_phrase\\nnoun_phrase => Article Adj* noun\\nAdj* => null | Adj Adj*\\nverb_phrase => verb noun_phrase\\nArticle =>  一个 | 这个\\nnoun =>   女人 |  篮球 | 桌子 | 小猫\\nverb => 看着   |  坐在 |  听着 | 看见\\nAdj =>  蓝色的 | 好看的 | 小小的\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.573472Z",
     "start_time": "2019-06-30T23:40:20.565494Z"
    }
   },
   "outputs": [],
   "source": [
    "def adj(): return np.random.choice(list(map(lambda s: s.strip(), '蓝色的 | 好看的 | 小小的'.split('|'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.587434Z",
     "start_time": "2019-06-30T23:40:20.580455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好看的'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.594417Z",
     "start_time": "2019-06-30T23:40:20.589430Z"
    }
   },
   "outputs": [],
   "source": [
    "def adj_star(): return np.random.choice([lambda : '', lambda : adj()+adj_star()])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.603392Z",
     "start_time": "2019-06-30T23:40:20.596411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好看的蓝色的好看的小小的好看的蓝色的蓝色的'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_star()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.612369Z",
     "start_time": "2019-06-30T23:40:20.605386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['蓝色的', '好看的', '小小的']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda s: s.strip(), '蓝色的 | 好看的 | 小小的'.split('|')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.619350Z",
     "start_time": "2019-06-30T23:40:20.614362Z"
    }
   },
   "outputs": [],
   "source": [
    "adj_grammar = \"\"\"\n",
    "Adj* => null | Adj Adj*\n",
    "Adj =>  蓝色的 | 好看的 | 小小的\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.629323Z",
     "start_time": "2019-06-30T23:40:20.621343Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str, split_='=>', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue\n",
    "        k, v = line.split(split_)\n",
    "        grammar[k.strip()] = [s.split() for s in v.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.639308Z",
     "start_time": "2019-06-30T23:40:20.632316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adj*': [['null'], ['Adj', 'Adj*']], 'Adj': [['蓝色的'], ['好看的'], ['小小的']]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_grammar(adj_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.650266Z",
     "start_time": "2019-06-30T23:40:20.643290Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(gram, target):\n",
    "    if target not in gram: return target\n",
    "    expanded = [generate(gram, t) for t in random.choice(gram[target])]\n",
    "    return ''.join(s for s in expanded if s != 'null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.659243Z",
     "start_time": "2019-06-30T23:40:20.653258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': [['noun_phrase', 'verb_phrase']],\n",
       " 'noun_phrase': [['Article', 'Adj*', 'noun']],\n",
       " 'Adj*': [['null'], ['Adj', 'Adj*']],\n",
       " 'verb_phrase': [['verb', 'noun_phrase']],\n",
       " 'Article': [['一个'], ['这个']],\n",
       " 'noun': [['女人'], ['篮球'], ['桌子'], ['小猫']],\n",
       " 'verb': [['看着'], ['坐在'], ['听着'], ['看见']],\n",
       " 'Adj': [['蓝色的'], ['好看的'], ['小小的']]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_grammar = create_grammar(simple_grammar)\n",
    "example_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.669216Z",
     "start_time": "2019-06-30T23:40:20.662235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这个好看的女人看见一个好看的女人'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(example_grammar, 'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:40:20.677215Z",
     "start_time": "2019-06-30T23:40:20.673205Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:56:36.172779Z",
     "start_time": "2019-06-30T23:56:35.587763Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../../Lesson01/article_9k.txt', 'r') as f:\n",
    "    articles = list(map(lambda s: s.strip('\\n'), f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:56:45.667834Z",
     "start_time": "2019-06-30T23:56:45.663810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体验版内测稳定版暂不受影响以确保工程师可以集中全部精力进行系统优化工作有人猜测这也是将精力主要用到MIUI9的研发之中MIUI8去年5月发布距今已有一年有余也是时候更新换代了当然关于MIUI9的确切信息我们还是等待官方消息',\n",
       " '骁龙835作为唯一通过Windows10桌面平台认证的ARM处理器高通强调不会因为只考虑性能而去屏蔽掉小核心相反他们正联手微软找到一种适合桌面平台的兼顾性能和功耗的完美方案报道称微软已经拿到了一些新的源码以便Windows10更好地理解biglittle架构资料显示骁龙835作为一款集成了CPUGPU基带蓝牙WiFi的SoC比传统的Wintel方案可以节省至少30的PCB空间按计划今年Q4华硕惠普联想将首发骁龙835Win10电脑预计均是二合一形态的产品当然高通骁龙只是个开始未来也许还能见到三星Exynos联发科华为麒麟小米澎湃等进入Windows10桌面平台']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:56:46.435532Z",
     "start_time": "2019-06-30T23:56:45.669795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\xxx\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.752 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "with_jieba_cut = Counter(jieba.cut(articles[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:56:46.445506Z",
     "start_time": "2019-06-30T23:56:46.437526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'骁龙': 4,\n",
       "         '835': 2,\n",
       "         '作为': 2,\n",
       "         '唯一': 1,\n",
       "         '通过': 1,\n",
       "         'Windows10': 3,\n",
       "         '桌面': 3,\n",
       "         '平台': 3,\n",
       "         '认证': 1,\n",
       "         '的': 8,\n",
       "         'ARM': 1,\n",
       "         '处理器': 1,\n",
       "         '高通': 2,\n",
       "         '强调': 1,\n",
       "         '不会': 1,\n",
       "         '因为': 1,\n",
       "         '只': 1,\n",
       "         '考虑': 1,\n",
       "         '性能': 2,\n",
       "         '而': 1,\n",
       "         '去': 1,\n",
       "         '屏蔽掉': 1,\n",
       "         '小': 1,\n",
       "         '核心': 1,\n",
       "         '相反': 1,\n",
       "         '他们': 1,\n",
       "         '正': 1,\n",
       "         '联手': 1,\n",
       "         '微软': 2,\n",
       "         '找到': 1,\n",
       "         '一种': 1,\n",
       "         '适合': 1,\n",
       "         '兼顾': 1,\n",
       "         '和': 1,\n",
       "         '功耗': 1,\n",
       "         '完美': 1,\n",
       "         '方案': 2,\n",
       "         '报道': 1,\n",
       "         '称': 1,\n",
       "         '已经': 1,\n",
       "         '拿到': 1,\n",
       "         '了': 2,\n",
       "         '一些': 1,\n",
       "         '新': 1,\n",
       "         '源码': 1,\n",
       "         '以便': 1,\n",
       "         '更好': 1,\n",
       "         '地': 1,\n",
       "         '理解': 1,\n",
       "         'biglittle': 1,\n",
       "         '架构': 1,\n",
       "         '资料': 1,\n",
       "         '显示': 1,\n",
       "         '一款': 1,\n",
       "         '集成': 1,\n",
       "         'CPUGPU': 1,\n",
       "         '基带': 1,\n",
       "         '蓝牙': 1,\n",
       "         'WiFi': 1,\n",
       "         'SoC': 1,\n",
       "         '比': 1,\n",
       "         '传统': 1,\n",
       "         'Wintel': 1,\n",
       "         '可以': 1,\n",
       "         '节省': 1,\n",
       "         '至少': 1,\n",
       "         '30': 1,\n",
       "         'PCB': 1,\n",
       "         '空间': 1,\n",
       "         '按计划': 1,\n",
       "         '今年': 1,\n",
       "         'Q4': 1,\n",
       "         '华硕': 1,\n",
       "         '惠普': 1,\n",
       "         '联想': 1,\n",
       "         '将': 1,\n",
       "         '首发': 1,\n",
       "         '835Win10': 1,\n",
       "         '电脑': 1,\n",
       "         '预计': 1,\n",
       "         '均': 1,\n",
       "         '是': 1,\n",
       "         '二合一': 1,\n",
       "         '形态': 1,\n",
       "         '产品': 1,\n",
       "         '当然': 1,\n",
       "         '只是': 1,\n",
       "         '个': 1,\n",
       "         '开始': 1,\n",
       "         '未来': 1,\n",
       "         '也许': 1,\n",
       "         '还': 1,\n",
       "         '能': 1,\n",
       "         '见到': 1,\n",
       "         '三星': 1,\n",
       "         'Exynos': 1,\n",
       "         '联发科': 1,\n",
       "         '华为': 1,\n",
       "         '麒麟': 1,\n",
       "         '小米': 1,\n",
       "         '澎湃': 1,\n",
       "         '等': 1,\n",
       "         '进入': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_jieba_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:56:46.452493Z",
     "start_time": "2019-06-30T23:56:46.448498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'骁龙835作为唯一通过Windows10桌面平台认证的ARM处理器高通强调不会因为只考虑性能而去屏蔽掉小核心相反他们正联手微软找到一种适合桌面平台的兼顾性能和功耗的完美方案报道称微软已经拿到了一些新的源码以便Windows10更好地理解biglittle架构资料显示骁龙835作为一款集成了CPUGPU基带蓝牙WiFi的SoC比传统的Wintel方案可以节省至少30的PCB空间按计划今年Q4华硕惠普联想将首发骁龙835Win10电脑预计均是二合一形态的产品当然高通骁龙只是个开始未来也许还能见到三星Exynos联发科华为麒麟小米澎湃等进入Windows10桌面平台'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:56:46.460465Z",
     "start_time": "2019-06-30T23:56:46.454482Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut(string): return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:17.939421Z",
     "start_time": "2019-06-30T23:56:46.462462Z"
    }
   },
   "outputs": [],
   "source": [
    "token = []\n",
    "for sentence in articles[:10000]:\n",
    "    token += cut(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:18.451346Z",
     "start_time": "2019-06-30T23:57:17.941218Z"
    }
   },
   "outputs": [],
   "source": [
    "words_count = Counter(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:18.499248Z",
     "start_time": "2019-06-30T23:57:18.452308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 184244),\n",
       " ('在', 47370),\n",
       " ('了', 36722),\n",
       " ('和', 30809),\n",
       " ('是', 30283),\n",
       " ('月', 18711),\n",
       " ('也', 15995),\n",
       " ('年', 15971),\n",
       " ('有', 14714),\n",
       " ('为', 14448),\n",
       " ('等', 14340),\n",
       " ('将', 14060),\n",
       " ('对', 13074),\n",
       " ('与', 12568),\n",
       " ('日', 12322),\n",
       " ('中', 11117),\n",
       " ('中国', 11036),\n",
       " ('6', 10477),\n",
       " ('上', 10192),\n",
       " ('不', 10027),\n",
       " ('他', 9530),\n",
       " ('都', 9447),\n",
       " ('发展', 8795),\n",
       " ('企业', 8584),\n",
       " ('就', 8537),\n",
       " ('到', 8338),\n",
       " ('市场', 8095),\n",
       " ('但', 7729),\n",
       " ('这', 7658),\n",
       " ('被', 7575),\n",
       " ('从', 7513),\n",
       " ('并', 7412),\n",
       " ('人', 7339),\n",
       " ('后', 7084),\n",
       " ('公司', 6915),\n",
       " ('一个', 6772),\n",
       " ('说', 6703),\n",
       " ('新', 6467),\n",
       " ('表示', 6309),\n",
       " ('要', 6276),\n",
       " ('还', 6245),\n",
       " ('会', 6179),\n",
       " ('个', 6176),\n",
       " ('我', 6141),\n",
       " ('而', 6090),\n",
       " ('进行', 5802),\n",
       " ('我们', 5742),\n",
       " ('记者', 5734),\n",
       " ('以', 5615),\n",
       " ('5', 5569),\n",
       " ('工作', 5135),\n",
       " ('没有', 5000),\n",
       " ('美国', 4840),\n",
       " ('下', 4741),\n",
       " ('更', 4739),\n",
       " ('通过', 4720),\n",
       " ('大', 4704),\n",
       " ('让', 4701),\n",
       " ('可以', 4681),\n",
       " ('经济', 4670),\n",
       " ('时', 4654),\n",
       " ('目前', 4645),\n",
       " ('国家', 4628),\n",
       " ('项目', 4538),\n",
       " ('问题', 4422),\n",
       " ('创新', 4416),\n",
       " ('多', 4410),\n",
       " ('已经', 4391),\n",
       " ('建设', 4373),\n",
       " ('其', 4224),\n",
       " ('自己', 4119),\n",
       " ('投资', 4064),\n",
       " ('已', 4026),\n",
       " ('3', 4008),\n",
       " ('城市', 3921),\n",
       " ('服务', 3842),\n",
       " ('报道', 3818),\n",
       " ('亿元', 3813),\n",
       " ('及', 3812),\n",
       " ('1', 3793),\n",
       " ('成为', 3684),\n",
       " ('相关', 3646),\n",
       " ('向', 3603),\n",
       " ('可能', 3595),\n",
       " ('他们', 3560),\n",
       " ('以及', 3475),\n",
       " ('或', 3447),\n",
       " ('今年', 3426),\n",
       " ('地', 3411),\n",
       " ('其中', 3408),\n",
       " ('于', 3371),\n",
       " ('她', 3349),\n",
       " ('能', 3343),\n",
       " ('10', 3330),\n",
       " ('着', 3327),\n",
       " ('2016', 3310),\n",
       " ('认为', 3295),\n",
       " ('20', 3282),\n",
       " ('称', 3271),\n",
       " ('把', 3257)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:18.510194Z",
     "start_time": "2019-06-30T23:57:18.506169Z"
    }
   },
   "outputs": [],
   "source": [
    "def prob_1(word, gram_1): return gram_1[word] / sum(gram_1.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:18.520167Z",
     "start_time": "2019-06-30T23:57:18.514142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015587203508559526"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_1('我们', words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:18.530100Z",
     "start_time": "2019-06-30T23:57:18.523122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外', '自', '本周', '6', '月', '12', '日起', '除', '小米', '手机']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:19.387805Z",
     "start_time": "2019-06-30T23:57:18.532095Z"
    }
   },
   "outputs": [],
   "source": [
    "token_2_gram = [token[i]+token[i+1] for i in range(len(token)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:19.393791Z",
     "start_time": "2019-06-30T23:57:19.388802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外自', '自本周', '本周6', '6月', '月12', '12日起', '日起除', '除小米', '小米手机', '手机6']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_2_gram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:20.803917Z",
     "start_time": "2019-06-30T23:57:19.395784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('6月', 8502),\n",
       " ('2016年', 2773),\n",
       " ('2017年', 2496),\n",
       " ('的是', 2250),\n",
       " ('5月', 2111),\n",
       " ('也是', 2054),\n",
       " ('nannan', 1740),\n",
       " ('都是', 1590),\n",
       " ('自己的', 1496),\n",
       " ('更多', 1490)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_2 = Counter(token_2_gram)\n",
    "words_count_2.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:20.862759Z",
     "start_time": "2019-06-30T23:57:20.805912Z"
    }
   },
   "outputs": [],
   "source": [
    "def prob_2(word1, word2, gram_2):\n",
    "    if word1 + word2 in gram_2: \n",
    "        return gram_2[word1+word2] / sum(gram_2.values())\n",
    "    else:\n",
    "        return 1 / len(gram_2.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:20.889687Z",
     "start_time": "2019-06-30T23:57:20.864754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7145955659796026e-07"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('在', '吃饭', words_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:20.914061Z",
     "start_time": "2019-06-30T23:57:20.892680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.696250329144712e-05"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('我们', '在', words_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:20.925990Z",
     "start_time": "2019-06-30T23:57:20.916061Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_probability(sentence, words_count=words_count_2):\n",
    "    words = cut(sentence)\n",
    "    \n",
    "    p = 1\n",
    "    for i in range(len(words)-1):\n",
    "        p *= prob_2(words[i], words[i+1], words_count)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:20.948942Z",
     "start_time": "2019-06-30T23:57:20.926988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.612475783065937e-37"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('小明今天抽奖抽到一台苹果手机', words_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:20.972880Z",
     "start_time": "2019-06-30T23:57:20.949925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2577973644162107e-38"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('小明今天抽奖抽到一架波音飞机', words_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:20.980844Z",
     "start_time": "2019-06-30T23:57:20.974860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.248991923502565e-19"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('洋葱奶昔来一杯', words_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:21.572347Z",
     "start_time": "2019-06-30T23:57:20.982838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 这个小猫坐在一个蓝色的好看的小小的小小的女人 with prob: 2.41701310586375e-62\n",
      "sentence: 这个小猫看着这个蓝色的小小的篮球 with prob: 4.3774304024705924e-44\n",
      "sentence: 这个好看的小小的蓝色的小猫坐在一个小小的好看的小猫 with prob: 5.247378381397239e-74\n",
      "sentence: 一个小猫看见这个小小的小小的小小的小猫 with prob: 1.3730328471437752e-44\n",
      "sentence: 一个篮球听着一个小小的好看的蓝色的篮球 with prob: 3.524536745174446e-58\n",
      "sentence: 这个小小的篮球看着一个蓝色的蓝色的蓝色的女人 with prob: 5.979487575686534e-65\n",
      "sentence: 这个篮球听着一个篮球 with prob: 4.5741167844965764e-30\n",
      "sentence: 这个小小的小小的女人坐在这个蓝色的桌子 with prob: 1.1927132412162692e-49\n",
      "sentence: 一个女人看见一个好看的女人 with prob: 5.124991413652614e-36\n",
      "sentence: 这个小猫听着一个篮球 with prob: 4.5741167844965764e-30\n"
     ]
    }
   ],
   "source": [
    "for sen in [generate(gram=example_grammar, target='sentence') for _ in range(10)]:\n",
    "    print('sentence: {} with prob: {}'.format(sen, get_probability(sen, words_count_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:21.851652Z",
     "start_time": "2019-06-30T23:57:21.573343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天晚上请你吃大餐，我们一起吃日料 is more possible\n",
      "----今天晚上请你吃大餐，我们一起吃日料 with probability 9.886806225389095e-61\n",
      "----明天晚上请你吃大餐，我们一起吃苹果 with probability 9.886806225389093e-61\n",
      "真是一只好看的小猫 is more possible\n",
      "----真事一只好看的小猫 with probability 1.8230175590384903e-31\n",
      "----真是一只好看的小猫 with probability 2.997746374854626e-25\n",
      "今晚我去吃火锅 is more possible\n",
      "----今晚我去吃火锅 with probability 4.216444190595275e-18\n",
      "----今晚火锅去吃我 with probability 9.810806317706048e-25\n",
      "养乐多绿来一杯 is more possible\n",
      "----洋葱奶昔来一杯 with probability 2.248991923502565e-19\n",
      "----养乐多绿来一杯 with probability 3.698213082112612e-13\n"
     ]
    }
   ],
   "source": [
    "need_compared = [\n",
    "    \"今天晚上请你吃大餐，我们一起吃日料 明天晚上请你吃大餐，我们一起吃苹果\",\n",
    "    \"真事一只好看的小猫 真是一只好看的小猫\",\n",
    "    \"今晚我去吃火锅 今晚火锅去吃我\",\n",
    "    \"洋葱奶昔来一杯 养乐多绿来一杯\"\n",
    "]\n",
    "for s in need_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = map(get_probability, [s1, s2])\n",
    "    \n",
    "    better = s1 if p1 > p2 else s2\n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4+'{} with probability {}'.format(s1, p1))\n",
    "    print('-'*4+'{} with probability {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T09:57:27.921063Z",
     "start_time": "2019-07-01T09:57:27.912088Z"
    }
   },
   "source": [
    "0. Can you come up out 3 sceneraies which use AI methods? <br>\n",
    "Ans: 语音助手、无人驾驶、机器翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How do we use Github; Why do we use Jupyter and Pycharm? <br>\n",
    "Ans: \n",
    "    * use Github: 基本步骤：git add ... -> git commit -m ... -> git push origin ...\n",
    "    * 使用 Jupyter 可以快速方便地实现初步想法进行实验、方便进行可视化\n",
    "    * 使用 Pycharm 进行项目真正的开发，稳定而有效率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What's the Probability Model? <br>\n",
    "Ans: 概率模型是用来描述不同随机变量之间关系的数学模型，通常情况下刻画了一个或多个随机变量之间的相互非确定性的概率关系。从数学上讲，该模型通常被表达为 $\\displaystyle (Y,P)$，其中 $\\displaystyle Y$是观测集合用来描述可能的观测结果， $\\displaystyle P$是$\\displaystyle Y$对应的概率分布函数集合。若使用概率模型，一般而言需假设存在一个确定的分布$\\displaystyle P$生成观测数据$\\displaystyle Y$ (摘自 https://zh.wikipedia.org/wiki/%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Can you came up with some sceneraies at which we could use Probability Model? <br>\n",
    "Ans: 使用隐马尔可夫模型进行词性标注、使用贝叶斯模型进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match? <br>\n",
    "Ans: 使用概率会得到通用性更强的语言模型；基于解析和模式匹配的模型难以适应各种各样的模式，针对每一种模式都要重新写一套代码，比较繁琐、冗余"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What's the Language Model? <br>\n",
    "Ans: 简单来说语言模型就是计算一个句子的概率的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Can you came up with some sceneraies at which we could use Language Model? <br>\n",
    "Ans: 机器翻译、语音识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What's the 1-gram language model? <br>\n",
    "Ans: 假设我们有一个 $m$ 个词组成的句子，我们希望计算得到这个句子的概率 $p(w_1, w_2, ..., w_m)$，1-gram 语言模型假设当前词的出现仅和自己相关，根据链式法则，有：\n",
    "$$p(w_1,w_2,...,w_m)=p(w_1)*p(w_2)*p(w_3)......p(w_m)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. What's the disadvantages and advantages of 1-gram language model? <br>\n",
    "Ans: 1-gram 语言模型的优点是计算简单开销小；缺点是由于假设失去了句子中词与词之间的互相关联信息，丢失了大量有用信息，也就导致了模型产生了偏差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. What't the 2-gram models? <br>\n",
    "Ans: 假设我们有一个 $m$ 个词组成的句子，我们希望计算得到这个句子的概率 $p(w_1, w_2, ..., w_m)$，2-gram 语言模型假设当前词的出现仅和前一个词相关，根据链式法则，有：\n",
    "$$p(w_1,w_2,...,w_m)=p(w_1)*p(w_2|w_1)*p(w_3|w_2)......p(w_m|w_{m-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 设计自己的句子生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:21.858635Z",
     "start_time": "2019-06-30T23:57:21.852650Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_n(grammar, target, n):\n",
    "    res = []\n",
    "    for _ in range(n):\n",
    "        res.append(generate(grammar, target))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:21.864617Z",
     "start_time": "2019-06-30T23:57:21.860629Z"
    }
   },
   "outputs": [],
   "source": [
    "singer = \"\"\"\n",
    "singer = 姓名 程度副词* 擅长 特点\n",
    "姓名 = 华晨宇 | 毛不易\n",
    "程度副词* = null | 程度副词 程度副词*\n",
    "程度副词 = 很 | 非常 | 特别 | 极其\n",
    "擅长 = 喜欢 | 善于 | 擅长\n",
    "特点 = 作词 | 作曲 | 喝酒 | 怼人\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:21.873594Z",
     "start_time": "2019-06-30T23:57:21.866647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'singer': [['姓名', '程度副词*', '擅长', '特点']],\n",
       " '姓名': [['华晨宇'], ['毛不易']],\n",
       " '程度副词*': [['null'], ['程度副词', '程度副词*']],\n",
       " '程度副词': [['很'], ['非常'], ['特别'], ['极其']],\n",
       " '擅长': [['喜欢'], ['善于'], ['擅长']],\n",
       " '特点': [['作词'], ['作曲'], ['喝酒'], ['怼人']]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singer_grammar = create_grammar(singer, split_='=')\n",
    "singer_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:21.881571Z",
     "start_time": "2019-06-30T23:57:21.875587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'华晨宇喜欢作词'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(singer_grammar, 'singer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:21.887572Z",
     "start_time": "2019-06-30T23:57:21.882568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['华晨宇特别很极其特别喜欢作词',\n",
       " '毛不易很很善于作曲',\n",
       " '华晨宇极其很喜欢喝酒',\n",
       " '华晨宇非常很很喜欢喝酒',\n",
       " '华晨宇善于怼人',\n",
       " '华晨宇很很善于喝酒']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(singer_grammar, 'singer', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:21.894570Z",
     "start_time": "2019-06-30T23:57:21.889551Z"
    }
   },
   "outputs": [],
   "source": [
    "self_introduction = \"\"\"\n",
    "self_introduction = 礼貌称呼 报姓名 来处 主修 喜欢 具体爱好*\n",
    "礼貌称呼 = null | 您好， | 你们好， | 老师们好，\n",
    "报姓名 = 我 动词 姓名\n",
    "动词 = 是 | 叫\n",
    "姓名 = xhp， | bxf，\n",
    "来处 = 来自 学校\n",
    "学校 = 同济大学， | 华东师范大学， | 中南大学，\n",
    "主修 = null | 专业是 专业\n",
    "专业 = 植物学， | 采矿工程， | 土木工程，\n",
    "喜欢 = 喜欢 | 擅长 | 善于\n",
    "具体爱好* = 具体爱好 | 具体爱好*\n",
    "具体爱好 = 听歌 | 码代码 | 弹钢琴 | 画画 | 跑步 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:21.959363Z",
     "start_time": "2019-06-30T23:57:21.896532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_introduction': [['礼貌称呼', '报姓名', '来处', '主修', '喜欢', '具体爱好*']],\n",
       " '礼貌称呼': [['null'], ['您好，'], ['你们好，'], ['老师们好，']],\n",
       " '报姓名': [['我', '动词', '姓名']],\n",
       " '动词': [['是'], ['叫']],\n",
       " '姓名': [['xhp，'], ['bxf，']],\n",
       " '来处': [['来自', '学校']],\n",
       " '学校': [['同济大学，'], ['华东师范大学，'], ['中南大学，']],\n",
       " '主修': [['null'], ['专业是', '专业']],\n",
       " '专业': [['植物学，'], ['采矿工程，'], ['土木工程，']],\n",
       " '喜欢': [['喜欢'], ['擅长'], ['善于']],\n",
       " '具体爱好*': [['具体爱好'], ['具体爱好*']],\n",
       " '具体爱好': [['听歌'], ['码代码'], ['弹钢琴'], ['画画'], ['跑步']]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_introduction_grammar = create_grammar(self_introduction, split_='=')\n",
    "self_introduction_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:21.966345Z",
     "start_time": "2019-06-30T23:57:21.960361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'老师们好，我是xhp，来自同济大学，专业是土木工程，擅长码代码'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(self_introduction_grammar, 'self_introduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:21.973362Z",
     "start_time": "2019-06-30T23:57:21.968339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我叫xhp，来自华东师范大学，专业是植物学，擅长听歌',\n",
       " '我是xhp，来自中南大学，专业是采矿工程，擅长跑步',\n",
       " '我叫bxf，来自华东师范大学，专业是采矿工程，善于跑步',\n",
       " '您好，我是xhp，来自同济大学，善于码代码',\n",
       " '我是xhp，来自中南大学，擅长跑步']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(self_introduction_grammar, 'self_introduction', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:22.769778Z",
     "start_time": "2019-06-30T23:57:21.974334Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xxx\\Anaconda3\\envs\\daily\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (0,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "movie_comments = pd.read_csv('../../datasource-master/movie_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:22.939662Z",
     "start_time": "2019-06-30T23:57:22.770771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:22.952591Z",
     "start_time": "2019-06-30T23:57:22.940653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫到了脑残的地步，看了恶心想吐',\n",
       " '首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮番上场，视物理逻辑于不顾，不得不说有钱真好，随意胡闹',\n",
       " '吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋律，为了煽情而煽情，让人觉得他是个大做作、大谎言家。（7.29更新）片子整体不如湄公河行动，1.整体不够流畅，编剧有毒，台词尴尬；2.刻意做作的主旋律煽情显得如此不合时宜而又多余。',\n",
       " '凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。',\n",
       " '中二得很']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = movie_comments['comment'].tolist()\n",
    "comments[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:22.962559Z",
     "start_time": "2019-06-30T23:57:22.955577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:22.968544Z",
     "start_time": "2019-06-30T23:57:22.964570Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:23.043559Z",
     "start_time": "2019-06-30T23:57:22.971538Z"
    }
   },
   "outputs": [],
   "source": [
    "def token(comments):\n",
    "    res = []\n",
    "    for c in comments:\n",
    "        try:\n",
    "            res.append(''.join(re.findall('\\w+', c)))\n",
    "        except TypeError:\n",
    "            print(c)\n",
    "    return ''.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:23.731749Z",
     "start_time": "2019-06-30T23:57:23.060334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "tokens = token(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:57:23.742475Z",
     "start_time": "2019-06-30T23:57:23.738519Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'吴京意淫到了脑残的地步看了恶心想吐首映礼看的太恐怖了这个电影不讲道理的完全就是吴京在实现他这个小粉红的英雄梦各种装备轮番上场视物理逻辑于不顾不得不说有钱真好随意胡闹吴京的炒作水平不输冯小刚但小刚至少不'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:58:20.627672Z",
     "start_time": "2019-06-30T23:57:23.743472Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_cut = list(jieba.cut(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:58:21.235164Z",
     "start_time": "2019-06-30T23:58:20.629402Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_count = Counter(comments_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:58:21.275977Z",
     "start_time": "2019-06-30T23:58:21.237083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 328253),\n",
       " ('了', 102408),\n",
       " ('是', 73433),\n",
       " ('我', 50520),\n",
       " ('都', 36251),\n",
       " ('很', 34760),\n",
       " ('看', 33850),\n",
       " ('电影', 33638),\n",
       " ('也', 32064),\n",
       " ('和', 31291)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:58:22.377044Z",
     "start_time": "2019-06-30T23:58:21.277013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫', '意淫到', '到了', '了脑残', '脑残的', '的地步', '地步看', '看了', '了恶心', '恶心想']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_2_gram = [comments_cut[i]+comments_cut[i+1] for i in range(len(comments_cut)-1)]\n",
    "comments_2_gram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:58:23.723680Z",
     "start_time": "2019-06-30T23:58:22.378039Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_2_gram_count = Counter(comments_2_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:58:23.954111Z",
     "start_time": "2019-06-30T23:58:23.725674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的电影', 8631),\n",
       " ('看的', 7075),\n",
       " ('都是', 6335),\n",
       " ('让人', 5278),\n",
       " ('的故事', 4707),\n",
       " ('看了', 4538),\n",
       " ('也是', 4407),\n",
       " ('的时候', 4398),\n",
       " ('的是', 4348),\n",
       " ('的人', 4344)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_2_gram_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:58:23.978011Z",
     "start_time": "2019-06-30T23:58:23.956069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012458126542918915"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('好', '电影', comments_2_gram_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T23:58:24.246957Z",
     "start_time": "2019-06-30T23:58:23.980006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个电影真好看 is more possible\n",
      "****这个电影真好看 with probability 7.845413924131364e-14\n",
      "****这个电影正好看 with probability 1.1622835443157575e-17\n",
      "晚上一起去看电影啊 is more possible\n",
      "****晚上一起去看电影啊 with probability 1.6097900116028303e-23\n",
      "****一起去看晚上的电影啊 with probability 1.1082732920029169e-27\n"
     ]
    }
   ],
   "source": [
    "comments_compare = [\n",
    "    '这个电影真好看 这个电影正好看',\n",
    "    '晚上一起去看电影啊 一起去看晚上的电影啊'\n",
    "]\n",
    "for comment in comments_compare:\n",
    "    c1, c2 = comment.split()\n",
    "    p1, p2 = map(partial(get_probability, words_count=comments_2_gram_count), [c1, c2])\n",
    "    better = c1 if p1 > p2 else p2\n",
    "    print('{} is more possible'.format(better))\n",
    "    print('*'*4 + '{} with probability {}'.format(c1, p1))\n",
    "    print('*'*4 + '{} with probability {}'.format(c2, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T00:13:54.962251Z",
     "start_time": "2019-07-01T00:13:54.955267Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_best(grammar, language_model, target, n):\n",
    "    sentences = generate_n(grammar, target, n)\n",
    "    sentences_with_prob = sorted(zip(sentences, map(partial(get_probability, words_count=language_model), sentences)), key=lambda x: x[1])\n",
    "    print(sentences_with_prob)\n",
    "    return sentences_with_prob[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T00:15:29.502207Z",
     "start_time": "2019-07-01T00:15:29.376035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('老师们好，我是xhp，来自华东师范大学，专业是采矿工程，善于弹钢琴', 3.8936624018780276e-97), ('你们好，我是bxf，来自华东师范大学，专业是植物学，善于画画', 1.9598211590804072e-85), ('您好，我是bxf，来自同济大学，专业是植物学，擅长跑步', 1.9598211590804072e-85), ('你们好，我是bxf，来自中南大学，擅长跑步', 1.8942295322765524e-60), ('我叫bxf，来自中南大学，擅长跑步', 1.850824861550177e-49)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我叫bxf，来自中南大学，擅长跑步'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(self_introduction_grammar, comments_2_gram_count, 'self_introduction', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q: 这个模型有什么问题？ 你准备如何提升？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ans: \n",
    "1.语言模型不够全面，只是针对电影评论生成的，所以求得的句子合理的概率会有偏差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 完成基于Pattern Match的语句问答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T01:38:35.832059Z",
     "start_time": "2019-07-01T01:38:35.818094Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_variable(pat):\n",
    "    return pat.startswith('?') and all(s.isalpha() for s in pat[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T01:56:01.801224Z",
     "start_time": "2019-07-01T01:56:01.794244Z"
    }
   },
   "outputs": [],
   "source": [
    "def pat_match(pattern, saying):\n",
    "    if is_variable(pattern[0]): return pattern[0], saying[0]\n",
    "    else:\n",
    "        if pattern[0] != saying[0]: return '', ''\n",
    "        else: return pat_match(pattern[1:], saying[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T01:57:24.105328Z",
     "start_time": "2019-07-01T01:57:24.098385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('?', 'jkljas')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match('?'.split(), 'jkljas hkjaks'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:04:43.739372Z",
     "start_time": "2019-07-01T02:04:43.729387Z"
    }
   },
   "outputs": [],
   "source": [
    "def pat_match(pattern, saying):\n",
    "    if not pattern or not saying: return []\n",
    "    if is_variable(pattern[0]): \n",
    "        return [(pattern[0], saying[0])] + pat_match(pattern[1:], saying[1:])\n",
    "    elif pattern[0] != saying[0]:\n",
    "        return []\n",
    "    else:\n",
    "        return pat_match(pattern[1:], saying[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:17:18.608286Z",
     "start_time": "2019-07-01T02:17:18.600273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?X', '3'), ('?Y', '2')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match(\"?X greater than ?Y\".split(), \"3 greater than 2\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:18:11.397095Z",
     "start_time": "2019-07-01T02:18:11.391148Z"
    }
   },
   "outputs": [],
   "source": [
    "def pat_to_dict(patterns):\n",
    "    return {k: v for k, v in patterns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:23:55.356852Z",
     "start_time": "2019-07-01T02:23:55.349871Z"
    }
   },
   "outputs": [],
   "source": [
    "def substitute(rule, parsed_rules):\n",
    "    if not rule: return []\n",
    "    return [parsed_rules.get(rule[0], rule[0])]+substitute(rule[1:], parsed_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:24:05.761839Z",
     "start_time": "2019-07-01T02:24:05.754856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?X', 'iPhone')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_patterns = pat_match(\"I want ?X\".split(), \"I want iPhone\".split())\n",
    "got_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:24:16.219166Z",
     "start_time": "2019-07-01T02:24:16.215141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'if', 'you', 'mean', 'if', 'you', 'got', 'a', 'iPhone']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute(\"What if you mean if you got a ?X\".split(), pat_to_dict(got_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:25:14.641294Z",
     "start_time": "2019-07-01T02:25:14.636296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?P', 'John'), ('?X', 'resting')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_pat = pat_match('?P needs ?X'.split(), \"John needs resting\".split())\n",
    "john_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:25:31.536901Z",
     "start_time": "2019-07-01T02:25:31.531902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What if you mean if you got a iPhone'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(substitute(\"What if you mean if you got a ?X\".split(), pat_to_dict(got_patterns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:25:57.180435Z",
     "start_time": "2019-07-01T02:25:57.174486Z"
    }
   },
   "outputs": [],
   "source": [
    "john_pat = pat_match('?P needs ?X'.split(), \"John needs vacation\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:26:40.887373Z",
     "start_time": "2019-07-01T02:26:40.882386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['why', 'does', 'John', 'need', 'vacation', '?']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute('why does ?P need ?X ?'.split(), pat_to_dict(john_pat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:26:59.262759Z",
     "start_time": "2019-07-01T02:26:59.255741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why does John need vacation ?'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(substitute('why does ?P need ?X ?'.split(), pat_to_dict(john_pat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:40:43.184939Z",
     "start_time": "2019-07-01T02:40:43.174728Z"
    }
   },
   "outputs": [],
   "source": [
    "defined_patterns = {\n",
    "    \"I need ?X\": [\"Image you will get ?X soon\", \"Why do you need ?X ?\"], \n",
    "    \"My ?X told me something\": [\"Talk about more about your ?X\", \"How do you think about your ?X ?\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T03:13:26.466671Z",
     "start_time": "2019-07-01T03:13:26.459652Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_response(saying, rules):\n",
    "    for q, a in rules.items():\n",
    "        parsed_rules = pat_match(q.split(), saying.split())\n",
    "        if parsed_rules:\n",
    "            resp = np.random.choice(a)\n",
    "            return ' '.join(substitute(resp.split(), pat_to_dict(parsed_rules)))\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:52:43.055733Z",
     "start_time": "2019-07-01T02:52:43.048752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do you need iPhone ?'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('I need iPhone', defined_patterns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:53:34.695921Z",
     "start_time": "2019-07-01T02:53:34.691896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Talk about more about your mother'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"My mother told me something\", defined_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segment Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:58:05.270119Z",
     "start_time": "2019-07-01T02:58:05.264131Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_pattern_segment(pattern):\n",
    "    return pattern.startswith('?*') and all(a.isalpha() for a in pattern[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T03:00:48.588620Z",
     "start_time": "2019-07-01T03:00:48.584629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pattern_segment('?*P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T03:01:17.204127Z",
     "start_time": "2019-07-01T03:01:17.201103Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:28:54.812782Z",
     "start_time": "2019-07-01T07:28:54.805800Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_match(rest, saying):\n",
    "    if not rest or not saying:\n",
    "        return True\n",
    "#     elif not rest: return False\n",
    "#     elif not saying: return False\n",
    "    elif not all(s.isalpha() for s in rest[0]): # 如果当前 pattern 第一个是 variable 或者 pattern_segment，则后面的匹配可交给下一次继续进行\n",
    "        return True\n",
    "    elif rest[0] != saying[0]:\n",
    "        return False\n",
    "    else:\n",
    "        return is_match(rest[1:], saying[1:])\n",
    "\n",
    "def segment_match(pattern, saying):\n",
    "    seg_pat, rest = pattern[0], pattern[1:]\n",
    "    seg_pat = seg_pat.replace('?*', '?')\n",
    "    \n",
    "    if not rest: return (seg_pat, saying), len(saying)\n",
    "    \n",
    "    for i, token in enumerate(saying):\n",
    "        # 扩增到直至后面的可匹配\n",
    "        if rest[0] == token and is_match(rest[1:], saying[i+1:]):\n",
    "#             print(token, seg_pat)\n",
    "            return (seg_pat, saying[:i]), i\n",
    "    return (seg_pat, saying), len(saying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:28:22.333541Z",
     "start_time": "2019-07-01T07:28:22.327562Z"
    }
   },
   "outputs": [],
   "source": [
    "fail = [True, None]\n",
    "\n",
    "def pat_match_with_seg(pattern, saying):\n",
    "    # 修改了此处，阻止\"?*X hello ?*Y\"和\"Hi, how do you do\"的匹配，即匹配不允许saying或pattern有剩余，有剩余即为不能匹配\n",
    "    if not pattern and not saying: return []\n",
    "    elif not pattern: return fail\n",
    "    elif not saying and all(s.isalpha() for s in pattern[0]): return fail\n",
    "    pat = pattern[0]\n",
    "    if is_variable(pat):\n",
    "        return [(pat, saying[0])] + pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    elif is_pattern_segment(pat):\n",
    "        match, index = segment_match(pattern, saying)\n",
    "        return [match] + pat_match_with_seg(pattern[1:], saying[index:])\n",
    "    elif pat == saying[0]:\n",
    "        return pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    else:\n",
    "        return fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:04:28.861638Z",
     "start_time": "2019-07-01T07:04:28.856648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('?P', ['My', 'dog', 'and', 'my', 'cat']), 5)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_match('?*P is very good'.split(), \"My dog and my cat is very good is very good\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:05:03.608964Z",
     "start_time": "2019-07-01T07:05:03.604014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?P', ['My', 'dog']), ('?X', ['my', 'cat', 'is', 'very', 'cute'])]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match_with_seg('?*P is very good and ?*X'.split(), \"My dog is very good and my cat is very cute\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:05:14.070394Z",
     "start_time": "2019-07-01T07:05:14.065407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?X', ['an', 'iphone'])]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match_with_seg('I need ?*X'.split(), 'I need an iphone'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:05:24.837724Z",
     "start_time": "2019-07-01T07:05:24.831739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why', 'do', 'you', 'neeed', 'an iPhone']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute(\"Why do you neeed ?X\".split(), pat_to_dict(pat_match_with_seg('I need ?*X'.split(), \n",
    "                  \"I need an iPhone\".split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:05:35.395526Z",
     "start_time": "2019-07-01T07:05:35.391536Z"
    }
   },
   "outputs": [],
   "source": [
    "def pat_to_dict(patterns):\n",
    "    return {k: ' '.join(v) if isinstance(v, list) else v for k, v in patterns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T06:53:37.488340Z",
     "start_time": "2019-07-01T06:53:37.481347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why', 'do', 'you', 'neeed', 'an iPhone']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute(\"Why do you neeed ?X\".split(), pat_to_dict(pat_match_with_seg('I need ?*X'.split(), \n",
    "                  \"I need an iPhone\".split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:05:45.688179Z",
     "start_time": "2019-07-01T07:05:45.683156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?X', ['Hi,', 'how', 'do', 'you', 'do']), True, None]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match_with_seg(\"?*X hello ?*Y\".split(), \"Hi, how do you do\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T06:29:54.987618Z",
     "start_time": "2019-07-01T06:29:54.981674Z"
    }
   },
   "outputs": [],
   "source": [
    "rules = {\n",
    "    \"?*X hello ?*Y\": [\"Hi, how do you do?\"],\n",
    "    \"I was ?*X\": [\"Were you really ?X ?\", \"I already knew you were ?X .\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 问题1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:06:41.052240Z",
     "start_time": "2019-07-01T07:06:41.045247Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_response(saying, response_rules):\n",
    "    for q, a in response_rules.items():\n",
    "        match = pat_match_with_seg(q.split(), saying.split())\n",
    "        if match[-1] != None:\n",
    "            print(match)\n",
    "            resp = np.random.choice(a)\n",
    "            return ' '.join(substitute(resp.split(), pat_to_dict(match)))\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:07:25.108727Z",
     "start_time": "2019-07-01T07:07:25.102742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('?X', ['xhp'])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Were you really xhp ?'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('I was xhp', rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:29:05.398598Z",
     "start_time": "2019-07-01T07:29:05.393612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('?X', []), ('?Y', [])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi, how do you do?'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('hello', rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 问题2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T08:33:35.125036Z",
     "start_time": "2019-07-01T08:33:35.112071Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_chinese(sentence):\n",
    "    res = []\n",
    "    is_pattern = False\n",
    "    j = 0\n",
    "    for i in range(len(sentence)):\n",
    "        if not is_pattern and ord(sentence[i]) < 128:\n",
    "            tmp = sentence[j:i]\n",
    "            if tmp: res.append(tmp)\n",
    "            j = i\n",
    "            is_pattern = True\n",
    "        if is_pattern and ord(sentence[i]) >= 128:\n",
    "            tmp = sentence[j:i]\n",
    "            if tmp: res.append(tmp)\n",
    "            j = i\n",
    "            is_pattern = False\n",
    "    res.append(sentence[j:])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T08:33:45.690169Z",
     "start_time": "2019-07-01T08:33:45.685181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?*x', '我想要', '?*y']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_chinese('?*x我想要?*y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T09:27:18.772799Z",
     "start_time": "2019-07-01T09:27:18.763804Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut_chinese(sentence):\n",
    "    tokens = list(jieba.cut(sentence))\n",
    "    length = len(tokens)\n",
    "    i, j, res = 0, 0, []\n",
    "    while i < length:\n",
    "        if len(tokens[i]) > 1 or ord(tokens[i]) >= 128:\n",
    "            if i > j: \n",
    "                res.append(''.join(tokens[j:i]))\n",
    "                j = i\n",
    "            res.append(tokens[i])\n",
    "            j += 1\n",
    "        i += 1\n",
    "    if i > j: res.append(''.join(tokens[j:i]))\n",
    "    return res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T09:30:11.436102Z",
     "start_time": "2019-07-01T09:30:11.432074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?*x', '我', '想要', '?*y']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_chinese('?*x我想要?*y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T09:44:24.448398Z",
     "start_time": "2019-07-01T09:44:24.445404Z"
    }
   },
   "outputs": [],
   "source": [
    "def pat_to_dict(patterns):\n",
    "    return {k: ''.join(v) if isinstance(v, list) else v for k, v in patterns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T09:42:25.897993Z",
     "start_time": "2019-07-01T09:42:25.892968Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ch_response(saying, response_rules):\n",
    "    for q, a in response_rules.items():\n",
    "        match = pat_match_with_seg(cut(q), cut(saying))\n",
    "        if match[-1] != None:\n",
    "            resp = np.random.choice(a)\n",
    "            return ''.join(substitute(cut(resp), pat_to_dict(match)))\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T09:42:36.637148Z",
     "start_time": "2019-07-01T09:42:36.632159Z"
    }
   },
   "outputs": [],
   "source": [
    "chinese_rules = {\n",
    "    '?*x我想要?*y': ['?x想问你，你觉得?y有什么意义呢?', '为什么你想?y', '?x觉得... 你可以想想你很快就可以有?y了', '你看?x像?y不', '我看你就像?y'],\n",
    "    '?*x喜欢?*y': ['喜欢?y的哪里？', '?y有什么好的呢？', '你想要?y吗？'],\n",
    "    '?*x讨厌?*y': ['?y怎么会那么讨厌呢?', '讨厌?y的哪里？', '?y有什么不好呢？', '你不想要?y吗？']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T09:45:28.060101Z",
     "start_time": "2019-07-01T09:45:28.053119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'毕行风有什么好的呢？'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ch_response('我喜欢毕行风', chinese_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T09:47:06.568980Z",
     "start_time": "2019-07-01T09:47:06.559008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我看你就像一杯奶茶'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ch_response('我想要一杯奶茶', chinese_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
