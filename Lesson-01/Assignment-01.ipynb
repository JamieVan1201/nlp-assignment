{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 复现课堂代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:18.604692Z",
     "start_time": "2019-07-03T10:24:17.103447Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import random\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:19.932992Z",
     "start_time": "2019-07-03T10:24:19.929036Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_grammar = \"\"\"\n",
    "sentence => noun_phrase verb_phrase\n",
    "noun_phrase => Article Adj* noun\n",
    "Adj* => null | Adj Adj*\n",
    "verb_phrase => verb noun_phrase\n",
    "Article =>  一个 | 这个\n",
    "noun =>   女人 |  篮球 | 桌子 | 小猫\n",
    "verb => 看着   |  坐在 |  听着 | 看见\n",
    "Adj =>  蓝色的 | 好看的 | 小小的\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:24.969313Z",
     "start_time": "2019-07-03T10:24:24.963329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsentence => noun_phrase verb_phrase\\nnoun_phrase => Article Adj* noun\\nAdj* => null | Adj Adj*\\nverb_phrase => verb noun_phrase\\nArticle =>  一个 | 这个\\nnoun =>   女人 |  篮球 | 桌子 | 小猫\\nverb => 看着   |  坐在 |  听着 | 看见\\nAdj =>  蓝色的 | 好看的 | 小小的\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:25.985371Z",
     "start_time": "2019-07-03T10:24:25.981349Z"
    }
   },
   "outputs": [],
   "source": [
    "def adj(): return np.random.choice(list(map(lambda s: s.strip(), '蓝色的 | 好看的 | 小小的'.split('|'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:26.759249Z",
     "start_time": "2019-07-03T10:24:26.752271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好看的'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:27.486482Z",
     "start_time": "2019-07-03T10:24:27.480504Z"
    }
   },
   "outputs": [],
   "source": [
    "def adj_star(): return np.random.choice([lambda : '', lambda : adj()+adj_star()])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:28.334878Z",
     "start_time": "2019-07-03T10:24:28.327898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_star()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:29.190652Z",
     "start_time": "2019-07-03T10:24:29.183676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['蓝色的', '好看的', '小小的']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda s: s.strip(), '蓝色的 | 好看的 | 小小的'.split('|')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:30.227135Z",
     "start_time": "2019-07-03T10:24:30.223147Z"
    }
   },
   "outputs": [],
   "source": [
    "adj_grammar = \"\"\"\n",
    "Adj* => null | Adj Adj*\n",
    "Adj =>  蓝色的 | 好看的 | 小小的\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:31.105808Z",
     "start_time": "2019-07-03T10:24:31.095870Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str, split_='=>', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue\n",
    "        k, v = line.split(split_)\n",
    "        grammar[k.strip()] = [s.split() for s in v.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:31.936549Z",
     "start_time": "2019-07-03T10:24:31.931596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adj*': [['null'], ['Adj', 'Adj*']], 'Adj': [['蓝色的'], ['好看的'], ['小小的']]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_grammar(adj_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:24:51.148352Z",
     "start_time": "2019-07-03T10:24:51.144362Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(gram, target):\n",
    "    if target not in gram: return target\n",
    "    expanded = [generate(gram, t) for t in random.choice(gram[target])]\n",
    "    return ''.join(s for s in expanded if s != 'null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:25:10.810111Z",
     "start_time": "2019-07-03T10:25:10.803130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': [['noun_phrase', 'verb_phrase']],\n",
       " 'noun_phrase': [['Article', 'Adj*', 'noun']],\n",
       " 'Adj*': [['null'], ['Adj', 'Adj*']],\n",
       " 'verb_phrase': [['verb', 'noun_phrase']],\n",
       " 'Article': [['一个'], ['这个']],\n",
       " 'noun': [['女人'], ['篮球'], ['桌子'], ['小猫']],\n",
       " 'verb': [['看着'], ['坐在'], ['听着'], ['看见']],\n",
       " 'Adj': [['蓝色的'], ['好看的'], ['小小的']]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_grammar = create_grammar(simple_grammar)\n",
    "example_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:25:11.846196Z",
     "start_time": "2019-07-03T10:25:11.840229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这个篮球听着一个篮球'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(example_grammar, 'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:25:12.692716Z",
     "start_time": "2019-07-03T10:25:12.688762Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:25:14.353183Z",
     "start_time": "2019-07-03T10:25:13.761172Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../../Lesson01/article_9k.txt', 'r') as f:\n",
    "    articles = list(map(lambda s: s.strip('\\n'), f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:25:15.102016Z",
     "start_time": "2019-07-03T10:25:15.097059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体验版内测稳定版暂不受影响以确保工程师可以集中全部精力进行系统优化工作有人猜测这也是将精力主要用到MIUI9的研发之中MIUI8去年5月发布距今已有一年有余也是时候更新换代了当然关于MIUI9的确切信息我们还是等待官方消息',\n",
       " '骁龙835作为唯一通过Windows10桌面平台认证的ARM处理器高通强调不会因为只考虑性能而去屏蔽掉小核心相反他们正联手微软找到一种适合桌面平台的兼顾性能和功耗的完美方案报道称微软已经拿到了一些新的源码以便Windows10更好地理解biglittle架构资料显示骁龙835作为一款集成了CPUGPU基带蓝牙WiFi的SoC比传统的Wintel方案可以节省至少30的PCB空间按计划今年Q4华硕惠普联想将首发骁龙835Win10电脑预计均是二合一形态的产品当然高通骁龙只是个开始未来也许还能见到三星Exynos联发科华为麒麟小米澎湃等进入Windows10桌面平台']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:25:17.239243Z",
     "start_time": "2019-07-03T10:25:16.483722Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\xxx\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.749 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "with_jieba_cut = Counter(jieba.cut(articles[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:25:17.962664Z",
     "start_time": "2019-07-03T10:25:17.954685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'骁龙': 4,\n",
       "         '835': 2,\n",
       "         '作为': 2,\n",
       "         '唯一': 1,\n",
       "         '通过': 1,\n",
       "         'Windows10': 3,\n",
       "         '桌面': 3,\n",
       "         '平台': 3,\n",
       "         '认证': 1,\n",
       "         '的': 8,\n",
       "         'ARM': 1,\n",
       "         '处理器': 1,\n",
       "         '高通': 2,\n",
       "         '强调': 1,\n",
       "         '不会': 1,\n",
       "         '因为': 1,\n",
       "         '只': 1,\n",
       "         '考虑': 1,\n",
       "         '性能': 2,\n",
       "         '而': 1,\n",
       "         '去': 1,\n",
       "         '屏蔽掉': 1,\n",
       "         '小': 1,\n",
       "         '核心': 1,\n",
       "         '相反': 1,\n",
       "         '他们': 1,\n",
       "         '正': 1,\n",
       "         '联手': 1,\n",
       "         '微软': 2,\n",
       "         '找到': 1,\n",
       "         '一种': 1,\n",
       "         '适合': 1,\n",
       "         '兼顾': 1,\n",
       "         '和': 1,\n",
       "         '功耗': 1,\n",
       "         '完美': 1,\n",
       "         '方案': 2,\n",
       "         '报道': 1,\n",
       "         '称': 1,\n",
       "         '已经': 1,\n",
       "         '拿到': 1,\n",
       "         '了': 2,\n",
       "         '一些': 1,\n",
       "         '新': 1,\n",
       "         '源码': 1,\n",
       "         '以便': 1,\n",
       "         '更好': 1,\n",
       "         '地': 1,\n",
       "         '理解': 1,\n",
       "         'biglittle': 1,\n",
       "         '架构': 1,\n",
       "         '资料': 1,\n",
       "         '显示': 1,\n",
       "         '一款': 1,\n",
       "         '集成': 1,\n",
       "         'CPUGPU': 1,\n",
       "         '基带': 1,\n",
       "         '蓝牙': 1,\n",
       "         'WiFi': 1,\n",
       "         'SoC': 1,\n",
       "         '比': 1,\n",
       "         '传统': 1,\n",
       "         'Wintel': 1,\n",
       "         '可以': 1,\n",
       "         '节省': 1,\n",
       "         '至少': 1,\n",
       "         '30': 1,\n",
       "         'PCB': 1,\n",
       "         '空间': 1,\n",
       "         '按计划': 1,\n",
       "         '今年': 1,\n",
       "         'Q4': 1,\n",
       "         '华硕': 1,\n",
       "         '惠普': 1,\n",
       "         '联想': 1,\n",
       "         '将': 1,\n",
       "         '首发': 1,\n",
       "         '835Win10': 1,\n",
       "         '电脑': 1,\n",
       "         '预计': 1,\n",
       "         '均': 1,\n",
       "         '是': 1,\n",
       "         '二合一': 1,\n",
       "         '形态': 1,\n",
       "         '产品': 1,\n",
       "         '当然': 1,\n",
       "         '只是': 1,\n",
       "         '个': 1,\n",
       "         '开始': 1,\n",
       "         '未来': 1,\n",
       "         '也许': 1,\n",
       "         '还': 1,\n",
       "         '能': 1,\n",
       "         '见到': 1,\n",
       "         '三星': 1,\n",
       "         'Exynos': 1,\n",
       "         '联发科': 1,\n",
       "         '华为': 1,\n",
       "         '麒麟': 1,\n",
       "         '小米': 1,\n",
       "         '澎湃': 1,\n",
       "         '等': 1,\n",
       "         '进入': 1})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_jieba_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:36:40.207819Z",
     "start_time": "2019-07-03T10:36:40.201834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'骁龙835作为唯一通过Windows10桌面平台认证的ARM处理器高通强调不会因为只考虑性能而去屏蔽掉小核心相反他们正联手微软找到一种适合桌面平台的兼顾性能和功耗的完美方案报道称微软已经拿到了一些新的源码以便Windows10更好地理解biglittle架构资料显示骁龙835作为一款集成了CPUGPU基带蓝牙WiFi的SoC比传统的Wintel方案可以节省至少30的PCB空间按计划今年Q4华硕惠普联想将首发骁龙835Win10电脑预计均是二合一形态的产品当然高通骁龙只是个开始未来也许还能见到三星Exynos联发科华为麒麟小米澎湃等进入Windows10桌面平台'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:36:45.620672Z",
     "start_time": "2019-07-03T10:36:45.614688Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut(string): return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:37:29.768470Z",
     "start_time": "2019-07-03T10:36:54.001157Z"
    }
   },
   "outputs": [],
   "source": [
    "token = []\n",
    "for sentence in articles[:10000]:\n",
    "    token += cut(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:37:35.960722Z",
     "start_time": "2019-07-03T10:37:35.356357Z"
    }
   },
   "outputs": [],
   "source": [
    "words_count = Counter(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:37:41.624258Z",
     "start_time": "2019-07-03T10:37:41.578379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 184244),\n",
       " ('在', 47370),\n",
       " ('了', 36722),\n",
       " ('和', 30809),\n",
       " ('是', 30283),\n",
       " ('月', 18711),\n",
       " ('也', 15995),\n",
       " ('年', 15971),\n",
       " ('有', 14714),\n",
       " ('为', 14448),\n",
       " ('等', 14340),\n",
       " ('将', 14060),\n",
       " ('对', 13074),\n",
       " ('与', 12568),\n",
       " ('日', 12322),\n",
       " ('中', 11117),\n",
       " ('中国', 11036),\n",
       " ('6', 10477),\n",
       " ('上', 10192),\n",
       " ('不', 10027),\n",
       " ('他', 9530),\n",
       " ('都', 9447),\n",
       " ('发展', 8795),\n",
       " ('企业', 8584),\n",
       " ('就', 8537),\n",
       " ('到', 8338),\n",
       " ('市场', 8095),\n",
       " ('但', 7729),\n",
       " ('这', 7658),\n",
       " ('被', 7575),\n",
       " ('从', 7513),\n",
       " ('并', 7412),\n",
       " ('人', 7339),\n",
       " ('后', 7084),\n",
       " ('公司', 6915),\n",
       " ('一个', 6772),\n",
       " ('说', 6703),\n",
       " ('新', 6467),\n",
       " ('表示', 6309),\n",
       " ('要', 6276),\n",
       " ('还', 6245),\n",
       " ('会', 6179),\n",
       " ('个', 6176),\n",
       " ('我', 6141),\n",
       " ('而', 6090),\n",
       " ('进行', 5802),\n",
       " ('我们', 5742),\n",
       " ('记者', 5734),\n",
       " ('以', 5615),\n",
       " ('5', 5569),\n",
       " ('工作', 5135),\n",
       " ('没有', 5000),\n",
       " ('美国', 4840),\n",
       " ('下', 4741),\n",
       " ('更', 4739),\n",
       " ('通过', 4720),\n",
       " ('大', 4704),\n",
       " ('让', 4701),\n",
       " ('可以', 4681),\n",
       " ('经济', 4670),\n",
       " ('时', 4654),\n",
       " ('目前', 4645),\n",
       " ('国家', 4628),\n",
       " ('项目', 4538),\n",
       " ('问题', 4422),\n",
       " ('创新', 4416),\n",
       " ('多', 4410),\n",
       " ('已经', 4391),\n",
       " ('建设', 4373),\n",
       " ('其', 4224),\n",
       " ('自己', 4119),\n",
       " ('投资', 4064),\n",
       " ('已', 4026),\n",
       " ('3', 4008),\n",
       " ('城市', 3921),\n",
       " ('服务', 3842),\n",
       " ('报道', 3818),\n",
       " ('亿元', 3813),\n",
       " ('及', 3812),\n",
       " ('1', 3793),\n",
       " ('成为', 3684),\n",
       " ('相关', 3646),\n",
       " ('向', 3603),\n",
       " ('可能', 3595),\n",
       " ('他们', 3560),\n",
       " ('以及', 3475),\n",
       " ('或', 3447),\n",
       " ('今年', 3426),\n",
       " ('地', 3411),\n",
       " ('其中', 3408),\n",
       " ('于', 3371),\n",
       " ('她', 3349),\n",
       " ('能', 3343),\n",
       " ('10', 3330),\n",
       " ('着', 3327),\n",
       " ('2016', 3310),\n",
       " ('认为', 3295),\n",
       " ('20', 3282),\n",
       " ('称', 3271),\n",
       " ('把', 3257)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:37:47.812780Z",
     "start_time": "2019-07-03T10:37:47.807762Z"
    }
   },
   "outputs": [],
   "source": [
    "def prob_1(word, gram_1): \n",
    "    if word in gram_1:\n",
    "        return gram_1[word] / sum(gram_1.values())\n",
    "    else:\n",
    "        return 1 / sum(gram_1.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:37:53.606116Z",
     "start_time": "2019-07-03T10:37:53.599135Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015587203508559526"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_1('我们', words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:37:59.362964Z",
     "start_time": "2019-07-03T10:37:59.358966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外', '自', '本周', '6', '月', '12', '日起', '除', '小米', '手机']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:38:17.602792Z",
     "start_time": "2019-07-03T10:38:16.687736Z"
    }
   },
   "outputs": [],
   "source": [
    "token_2_gram = [token[i]+token[i+1] for i in range(len(token)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:38:23.042907Z",
     "start_time": "2019-07-03T10:38:23.036923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外自', '自本周', '本周6', '6月', '月12', '12日起', '日起除', '除小米', '小米手机', '手机6']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_2_gram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:38:29.886641Z",
     "start_time": "2019-07-03T10:38:28.412628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('6月', 8502),\n",
       " ('2016年', 2773),\n",
       " ('2017年', 2496),\n",
       " ('的是', 2250),\n",
       " ('5月', 2111),\n",
       " ('也是', 2054),\n",
       " ('nannan', 1740),\n",
       " ('都是', 1590),\n",
       " ('自己的', 1496),\n",
       " ('更多', 1490)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_2 = Counter(token_2_gram)\n",
    "words_count_2.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:38:35.362126Z",
     "start_time": "2019-07-03T10:38:35.357137Z"
    }
   },
   "outputs": [],
   "source": [
    "def prob_2(word1, word2, gram_2):\n",
    "    if word1 + word2 in gram_2: \n",
    "        return gram_2[word1+word2] / sum(gram_2.values())\n",
    "    else:\n",
    "        return 1 / len(gram_2.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:38:40.880300Z",
     "start_time": "2019-07-03T10:38:40.856365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7145955659796026e-07"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('在', '吃饭', words_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:38:46.287485Z",
     "start_time": "2019-07-03T10:38:46.266540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.696250329144712e-05"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('我们', '在', words_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:38:51.782790Z",
     "start_time": "2019-07-03T10:38:51.686019Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_probability(sentence, words_count=words_count_2):\n",
    "    words = cut(sentence)\n",
    "    \n",
    "    p = 1\n",
    "    for i in range(len(words)-1):\n",
    "        p *= prob_2(words[i], words[i+1], words_count)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:38:57.168573Z",
     "start_time": "2019-07-03T10:38:57.145638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.612475783065937e-37"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('小明今天抽奖抽到一台苹果手机', words_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:39:02.651251Z",
     "start_time": "2019-07-03T10:39:02.623324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2577973644162107e-38"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('小明今天抽奖抽到一架波音飞机', words_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:39:10.844647Z",
     "start_time": "2019-07-03T10:39:10.839662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.248991923502565e-19"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('洋葱奶昔来一杯', words_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:39:16.783709Z",
     "start_time": "2019-07-03T10:39:16.306984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 一个女人坐在这个桌子 with prob: 2.4420414013856e-25\n",
      "sentence: 这个女人看见一个好看的好看的桌子 with prob: 2.865022888047629e-49\n",
      "sentence: 一个桌子听着这个蓝色的女人 with prob: 1.0623922120395758e-41\n",
      "sentence: 一个好看的女人坐在这个小猫 with prob: 3.2150284094994805e-36\n",
      "sentence: 这个桌子看着一个篮球 with prob: 1.3676780000708865e-25\n",
      "sentence: 这个桌子看着一个小猫 with prob: 1.3676780000708865e-25\n",
      "sentence: 一个桌子坐在一个蓝色的女人 with prob: 1.0437374988479743e-36\n",
      "sentence: 这个小小的桌子看见一个篮球 with prob: 7.425385269360559e-32\n",
      "sentence: 这个好看的好看的小猫看见一个小小的篮球 with prob: 1.3067283833037612e-55\n",
      "sentence: 一个蓝色的篮球听着一个好看的小猫 with prob: 1.9672201843191167e-53\n"
     ]
    }
   ],
   "source": [
    "for sen in [generate(gram=example_grammar, target='sentence') for _ in range(10)]:\n",
    "    print('sentence: {} with prob: {}'.format(sen, get_probability(sen, words_count_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:39:22.527669Z",
     "start_time": "2019-07-03T10:39:22.241433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天晚上请你吃大餐，我们一起吃日料 is more possible\n",
      "----今天晚上请你吃大餐，我们一起吃日料 with probability 9.886806225389095e-61\n",
      "----明天晚上请你吃大餐，我们一起吃苹果 with probability 9.886806225389093e-61\n",
      "真是一只好看的小猫 is more possible\n",
      "----真事一只好看的小猫 with probability 1.8230175590384903e-31\n",
      "----真是一只好看的小猫 with probability 2.997746374854626e-25\n",
      "今晚我去吃火锅 is more possible\n",
      "----今晚我去吃火锅 with probability 4.216444190595275e-18\n",
      "----今晚火锅去吃我 with probability 9.810806317706048e-25\n",
      "养乐多绿来一杯 is more possible\n",
      "----洋葱奶昔来一杯 with probability 2.248991923502565e-19\n",
      "----养乐多绿来一杯 with probability 3.698213082112612e-13\n"
     ]
    }
   ],
   "source": [
    "need_compared = [\n",
    "    \"今天晚上请你吃大餐，我们一起吃日料 明天晚上请你吃大餐，我们一起吃苹果\",\n",
    "    \"真事一只好看的小猫 真是一只好看的小猫\",\n",
    "    \"今晚我去吃火锅 今晚火锅去吃我\",\n",
    "    \"洋葱奶昔来一杯 养乐多绿来一杯\"\n",
    "]\n",
    "for s in need_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = map(get_probability, [s1, s2])\n",
    "    \n",
    "    better = s1 if p1 > p2 else s2\n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4+'{} with probability {}'.format(s1, p1))\n",
    "    print('-'*4+'{} with probability {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T09:57:27.921063Z",
     "start_time": "2019-07-01T09:57:27.912088Z"
    }
   },
   "source": [
    "0. Can you come up out 3 sceneraies which use AI methods? <br>\n",
    "Ans: 语音助手、无人驾驶、机器翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How do we use Github; Why do we use Jupyter and Pycharm? <br>\n",
    "Ans: \n",
    "    * use Github: 基本步骤：git add ... -> git commit -m ... -> git push origin ...\n",
    "    * 使用 Jupyter 可以快速方便地实现初步想法进行实验、方便进行可视化\n",
    "    * 使用 Pycharm 进行项目真正的开发，稳定而有效率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What's the Probability Model? <br>\n",
    "Ans: 概率模型是用来描述不同随机变量之间关系的数学模型，通常情况下刻画了一个或多个随机变量之间的相互非确定性的概率关系。从数学上讲，该模型通常被表达为 $\\displaystyle (Y,P)$，其中 $\\displaystyle Y$是观测集合用来描述可能的观测结果， $\\displaystyle P$是$\\displaystyle Y$对应的概率分布函数集合。若使用概率模型，一般而言需假设存在一个确定的分布$\\displaystyle P$生成观测数据$\\displaystyle Y$ (摘自 https://zh.wikipedia.org/wiki/%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Can you came up with some sceneraies at which we could use Probability Model? <br>\n",
    "Ans: 使用隐马尔可夫模型进行词性标注、使用贝叶斯模型进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match? <br>\n",
    "Ans: 使用概率会得到通用性更强的语言模型；基于解析和模式匹配的模型难以适应各种各样的模式，针对每一种模式都要重新写一套代码，比较繁琐、冗余"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What's the Language Model? <br>\n",
    "Ans: 简单来说语言模型就是计算一个句子的概率的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Can you came up with some sceneraies at which we could use Language Model? <br>\n",
    "Ans: 机器翻译、语音识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What's the 1-gram language model? <br>\n",
    "Ans: 假设我们有一个 $m$ 个词组成的句子，我们希望计算得到这个句子的概率 $p(w_1, w_2, ..., w_m)$，1-gram 语言模型假设当前词的出现仅和自己相关，根据链式法则，有：\n",
    "$$p(w_1,w_2,...,w_m)=p(w_1)*p(w_2)*p(w_3)......p(w_m)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. What's the disadvantages and advantages of 1-gram language model? <br>\n",
    "Ans: 1-gram 语言模型的优点是计算简单开销小；缺点是由于假设失去了句子中词与词之间的互相关联信息，丢失了大量有用信息，也就导致了模型产生了偏差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. What't the 2-gram models? <br>\n",
    "Ans: 假设我们有一个 $m$ 个词组成的句子，我们希望计算得到这个句子的概率 $p(w_1, w_2, ..., w_m)$，2-gram 语言模型假设当前词的出现仅和前一个词相关，根据链式法则，有：\n",
    "$$p(w_1,w_2,...,w_m)=p(w_1)*p(w_2|w_1)*p(w_3|w_2)......p(w_m|w_{m-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1 设计自己的句子生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:39:36.642898Z",
     "start_time": "2019-07-03T10:39:36.638876Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_n(grammar, target, n):\n",
    "    res = []\n",
    "    for _ in range(n):\n",
    "        res.append(generate(grammar, target))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:39:42.250740Z",
     "start_time": "2019-07-03T10:39:42.246750Z"
    }
   },
   "outputs": [],
   "source": [
    "singer = \"\"\"\n",
    "singer = 姓名 程度副词* 擅长 特点\n",
    "姓名 = 华晨宇 | 毛不易\n",
    "程度副词* = null | 程度副词 程度副词*\n",
    "程度副词 = 很 | 非常 | 特别 | 极其\n",
    "擅长 = 喜欢 | 善于 | 擅长\n",
    "特点 = 作词 | 作曲 | 喝酒 | 怼人\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:39:47.622221Z",
     "start_time": "2019-07-03T10:39:47.617233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'singer': [['姓名', '程度副词*', '擅长', '特点']],\n",
       " '姓名': [['华晨宇'], ['毛不易']],\n",
       " '程度副词*': [['null'], ['程度副词', '程度副词*']],\n",
       " '程度副词': [['很'], ['非常'], ['特别'], ['极其']],\n",
       " '擅长': [['喜欢'], ['善于'], ['擅长']],\n",
       " '特点': [['作词'], ['作曲'], ['喝酒'], ['怼人']]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singer_grammar = create_grammar(singer, split_='=')\n",
    "singer_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:40:17.162432Z",
     "start_time": "2019-07-03T10:40:17.157365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'华晨宇善于作曲'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(singer_grammar, 'singer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:40:22.758019Z",
     "start_time": "2019-07-03T10:40:22.751038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['毛不易喜欢作曲', '毛不易喜欢作词', '华晨宇非常非常善于作曲', '毛不易非常特别善于作词', '华晨宇善于作词', '毛不易善于怼人']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(singer_grammar, 'singer', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:40:28.184625Z",
     "start_time": "2019-07-03T10:40:28.180637Z"
    }
   },
   "outputs": [],
   "source": [
    "self_introduction = \"\"\"\n",
    "self_introduction = 礼貌称呼 报姓名 来处 主修 喜欢 具体爱好*\n",
    "礼貌称呼 = null | 您好， | 你们好， | 老师们好，\n",
    "报姓名 = 我 动词 姓名\n",
    "动词 = 是 | 叫\n",
    "姓名 = xhp， | bxf，\n",
    "来处 = 来自 学校\n",
    "学校 = 同济大学， | 华东师范大学， | 中南大学，\n",
    "主修 = null | 专业是 专业\n",
    "专业 = 植物学， | 采矿工程， | 土木工程，\n",
    "喜欢 = 喜欢 | 擅长 | 善于\n",
    "具体爱好* = 具体爱好 | 具体爱好*\n",
    "具体爱好 = 听歌 | 码代码 | 弹钢琴 | 画画 | 跑步 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:40:33.520932Z",
     "start_time": "2019-07-03T10:40:33.515924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_introduction': [['礼貌称呼', '报姓名', '来处', '主修', '喜欢', '具体爱好*']],\n",
       " '礼貌称呼': [['null'], ['您好，'], ['你们好，'], ['老师们好，']],\n",
       " '报姓名': [['我', '动词', '姓名']],\n",
       " '动词': [['是'], ['叫']],\n",
       " '姓名': [['xhp，'], ['bxf，']],\n",
       " '来处': [['来自', '学校']],\n",
       " '学校': [['同济大学，'], ['华东师范大学，'], ['中南大学，']],\n",
       " '主修': [['null'], ['专业是', '专业']],\n",
       " '专业': [['植物学，'], ['采矿工程，'], ['土木工程，']],\n",
       " '喜欢': [['喜欢'], ['擅长'], ['善于']],\n",
       " '具体爱好*': [['具体爱好'], ['具体爱好*']],\n",
       " '具体爱好': [['听歌'], ['码代码'], ['弹钢琴'], ['画画'], ['跑步']]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_introduction_grammar = create_grammar(self_introduction, split_='=')\n",
    "self_introduction_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:40:38.856274Z",
     "start_time": "2019-07-03T10:40:38.852276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'老师们好，我是bxf，来自中南大学，善于码代码'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(self_introduction_grammar, 'self_introduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:40:44.276332Z",
     "start_time": "2019-07-03T10:40:44.271311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['您好，我叫bxf，来自中南大学，善于画画',\n",
       " '我叫xhp，来自中南大学，擅长听歌',\n",
       " '我是xhp，来自中南大学，专业是土木工程，善于听歌',\n",
       " '你们好，我叫xhp，来自同济大学，擅长听歌',\n",
       " '你们好，我是bxf，来自同济大学，擅长码代码']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(self_introduction_grammar, 'self_introduction', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:40:57.622491Z",
     "start_time": "2019-07-03T10:40:56.878305Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xxx\\Anaconda3\\envs\\daily\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (0,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "movie_comments = pd.read_csv('../../datasource-master/movie_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:41:16.370317Z",
     "start_time": "2019-07-03T10:41:16.351362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:41:21.870747Z",
     "start_time": "2019-07-03T10:41:21.858778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫到了脑残的地步，看了恶心想吐',\n",
       " '首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮番上场，视物理逻辑于不顾，不得不说有钱真好，随意胡闹',\n",
       " '吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋律，为了煽情而煽情，让人觉得他是个大做作、大谎言家。（7.29更新）片子整体不如湄公河行动，1.整体不够流畅，编剧有毒，台词尴尬；2.刻意做作的主旋律煽情显得如此不合时宜而又多余。',\n",
       " '凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。',\n",
       " '中二得很']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = movie_comments['comment'].tolist()\n",
    "comments[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:41:27.612040Z",
     "start_time": "2019-07-03T10:41:27.606054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:41:33.324899Z",
     "start_time": "2019-07-03T10:41:33.319911Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:41:39.169110Z",
     "start_time": "2019-07-03T10:41:39.078353Z"
    }
   },
   "outputs": [],
   "source": [
    "def token(comments):\n",
    "    res = []\n",
    "    for c in comments:\n",
    "        try:\n",
    "            res.append(''.join(re.findall('\\w+', c)))\n",
    "        except TypeError:\n",
    "            print(c)\n",
    "    return ''.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:41:44.813670Z",
     "start_time": "2019-07-03T10:41:44.126508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "tokens = token(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:41:49.911166Z",
     "start_time": "2019-07-03T10:41:49.905186Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'吴京意淫到了脑残的地步看了恶心想吐首映礼看的太恐怖了这个电影不讲道理的完全就是吴京在实现他这个小粉红的英雄梦各种装备轮番上场视物理逻辑于不顾不得不说有钱真好随意胡闹吴京的炒作水平不输冯小刚但小刚至少不'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:42:58.764732Z",
     "start_time": "2019-07-03T10:41:54.912956Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_cut = list(jieba.cut(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:43:05.708405Z",
     "start_time": "2019-07-03T10:43:05.050159Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_count = Counter(comments_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:43:12.143908Z",
     "start_time": "2019-07-03T10:43:12.095037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 328253),\n",
       " ('了', 102408),\n",
       " ('是', 73433),\n",
       " ('我', 50520),\n",
       " ('都', 36251),\n",
       " ('很', 34760),\n",
       " ('看', 33850),\n",
       " ('电影', 33638),\n",
       " ('也', 32064),\n",
       " ('和', 31291)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:43:20.679615Z",
     "start_time": "2019-07-03T10:43:19.577055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫', '意淫到', '到了', '了脑残', '脑残的', '的地步', '地步看', '看了', '了恶心', '恶心想']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_2_gram = [comments_cut[i]+comments_cut[i+1] for i in range(len(comments_cut)-1)]\n",
    "comments_2_gram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:43:30.221017Z",
     "start_time": "2019-07-03T10:43:28.792695Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_2_gram_count = Counter(comments_2_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:43:41.458762Z",
     "start_time": "2019-07-03T10:43:41.194876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的电影', 8631),\n",
       " ('看的', 7075),\n",
       " ('都是', 6335),\n",
       " ('让人', 5278),\n",
       " ('的故事', 4707),\n",
       " ('看了', 4538),\n",
       " ('也是', 4407),\n",
       " ('的时候', 4398),\n",
       " ('的是', 4348),\n",
       " ('的人', 4344)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_2_gram_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:43:52.250870Z",
     "start_time": "2019-07-03T10:43:52.230890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012458126542918915"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('好', '电影', comments_2_gram_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:44:03.264247Z",
     "start_time": "2019-07-03T10:44:02.981006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个电影真好看 is more possible\n",
      "****这个电影真好看 with probability 7.845413924131364e-14\n",
      "****这个电影正好看 with probability 1.1622835443157575e-17\n",
      "晚上一起去看电影啊 is more possible\n",
      "****晚上一起去看电影啊 with probability 1.6097900116028303e-23\n",
      "****一起去看晚上的电影啊 with probability 1.1082732920029169e-27\n"
     ]
    }
   ],
   "source": [
    "comments_compare = [\n",
    "    '这个电影真好看 这个电影正好看',\n",
    "    '晚上一起去看电影啊 一起去看晚上的电影啊'\n",
    "]\n",
    "for comment in comments_compare:\n",
    "    c1, c2 = comment.split()\n",
    "    p1, p2 = map(partial(get_probability, words_count=comments_2_gram_count), [c1, c2])\n",
    "    better = c1 if p1 > p2 else p2\n",
    "    print('{} is more possible'.format(better))\n",
    "    print('*'*4 + '{} with probability {}'.format(c1, p1))\n",
    "    print('*'*4 + '{} with probability {}'.format(c2, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:44:14.152805Z",
     "start_time": "2019-07-03T10:44:14.146823Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_best(grammar, language_model, target, n):\n",
    "    sentences = generate_n(grammar, target, n)\n",
    "    sentences_with_prob = sorted(zip(sentences, map(partial(get_probability, words_count=language_model), sentences)), key=lambda x: x[1])\n",
    "    print(sentences_with_prob)\n",
    "    return sentences_with_prob[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:44:25.177863Z",
     "start_time": "2019-07-03T10:44:24.997345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('您好，我叫bxf，来自同济大学，专业是土木工程，擅长画画', 6.159437928538423e-87), ('你们好，我是xhp，来自中南大学，专业是土木工程，擅长画画', 1.9598211590804072e-85), ('老师们好，我叫bxf，来自华东师范大学，善于跑步', 1.1827667181040505e-73), ('老师们好，我叫xhp，来自华东师范大学，善于弹钢琴', 1.1827667181040505e-73), ('你们好，我叫xhp，来自中南大学，擅长画画', 5.953292815726307e-62)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你们好，我叫xhp，来自中南大学，擅长画画'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(self_introduction_grammar, comments_2_gram_count, 'self_introduction', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q: 这个模型有什么问题？ 你准备如何提升？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ans: <br>\n",
    "1.基于规则，只适用于特定的场景特定的角色，不够通用；生成的句子中所选用的词全部来源于语法定义中的列表，词源比较有限，生成的句子较为单一。如果仍然是在基于规则的基础上提升的话，只能定义更多更完整的语法，定义更加完整的待选词列表 <br>\n",
    "2.语言模型不够全面，只是针对电影评论生成的，所以求得的句子合理的概率会有偏差；增加语料库的丰富性、多样性 <br>\n",
    "3.完善语料库、增加语法的丰富性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 (Optional) 完成基于Pattern Match的语句问答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Pattern Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:45:11.090746Z",
     "start_time": "2019-07-03T10:45:11.085759Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_variable(pat):\n",
    "    return pat.startswith('?') and all(s.isalpha() for s in pat[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:45:21.985121Z",
     "start_time": "2019-07-03T10:45:21.980116Z"
    }
   },
   "outputs": [],
   "source": [
    "def pat_match(pattern, saying):\n",
    "    if is_variable(pattern[0]): return pattern[0], saying[0]\n",
    "    else:\n",
    "        if pattern[0] != saying[0]: return '', ''\n",
    "        else: return pat_match(pattern[1:], saying[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:45:32.761002Z",
     "start_time": "2019-07-03T10:45:32.756017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('?', 'jkljas')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match('?'.split(), 'jkljas hkjaks'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:45:53.189678Z",
     "start_time": "2019-07-03T10:45:53.184728Z"
    }
   },
   "outputs": [],
   "source": [
    "def pat_match(pattern, saying):\n",
    "    if not pattern or not saying: return []\n",
    "    if is_variable(pattern[0]): \n",
    "        return [(pattern[0], saying[0])] + pat_match(pattern[1:], saying[1:])\n",
    "    elif pattern[0] != saying[0]:\n",
    "        return []\n",
    "    else:\n",
    "        return pat_match(pattern[1:], saying[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:46:03.944873Z",
     "start_time": "2019-07-03T10:46:03.939850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?X', '3'), ('?Y', '2')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match(\"?X greater than ?Y\".split(), \"3 greater than 2\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:46:15.115609Z",
     "start_time": "2019-07-03T10:46:15.110622Z"
    }
   },
   "outputs": [],
   "source": [
    "def pat_to_dict(patterns):\n",
    "    return {k: v for k, v in patterns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:46:25.899310Z",
     "start_time": "2019-07-03T10:46:25.895295Z"
    }
   },
   "outputs": [],
   "source": [
    "def substitute(rule, parsed_rules):\n",
    "    if not rule: return []\n",
    "    return [parsed_rules.get(rule[0], rule[0])]+substitute(rule[1:], parsed_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:46:36.820916Z",
     "start_time": "2019-07-03T10:46:36.814917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?X', 'iPhone')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_patterns = pat_match(\"I want ?X\".split(), \"I want iPhone\".split())\n",
    "got_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:46:51.104521Z",
     "start_time": "2019-07-03T10:46:51.098537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'if', 'you', 'mean', 'if', 'you', 'got', 'a', 'iPhone']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute(\"What if you mean if you got a ?X\".split(), pat_to_dict(got_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:47:02.402108Z",
     "start_time": "2019-07-03T10:47:02.397120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?P', 'John'), ('?X', 'resting')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_pat = pat_match('?P needs ?X'.split(), \"John needs resting\".split())\n",
    "john_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:47:13.101814Z",
     "start_time": "2019-07-03T10:47:13.096830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What if you mean if you got a iPhone'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(substitute(\"What if you mean if you got a ?X\".split(), pat_to_dict(got_patterns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:47:23.834961Z",
     "start_time": "2019-07-03T10:47:23.829974Z"
    }
   },
   "outputs": [],
   "source": [
    "john_pat = pat_match('?P needs ?X'.split(), \"John needs vacation\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:47:34.538539Z",
     "start_time": "2019-07-03T10:47:34.531557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['why', 'does', 'John', 'need', 'vacation', '?']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute('why does ?P need ?X ?'.split(), pat_to_dict(john_pat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:47:45.299860Z",
     "start_time": "2019-07-03T10:47:45.292878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why does John need vacation ?'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(substitute('why does ?P need ?X ?'.split(), pat_to_dict(john_pat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:47:57.884880Z",
     "start_time": "2019-07-03T10:47:57.879925Z"
    }
   },
   "outputs": [],
   "source": [
    "defined_patterns = {\n",
    "    \"I need ?X\": [\"Image you will get ?X soon\", \"Why do you need ?X ?\"], \n",
    "    \"My ?X told me something\": [\"Talk about more about your ?X\", \"How do you think about your ?X ?\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:48:08.714950Z",
     "start_time": "2019-07-03T10:48:08.707968Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_response(saying, rules):\n",
    "    for q, a in rules.items():\n",
    "        parsed_rules = pat_match(q.split(), saying.split())\n",
    "        if parsed_rules:\n",
    "            resp = np.random.choice(a)\n",
    "            return ' '.join(substitute(resp.split(), pat_to_dict(parsed_rules)))\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:48:19.620819Z",
     "start_time": "2019-07-03T10:48:19.614835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do you need iPhone ?'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('I need iPhone', defined_patterns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:48:30.373172Z",
     "start_time": "2019-07-03T10:48:30.367187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do you think about your mother ?'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"My mother told me something\", defined_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segment Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:49:10.411464Z",
     "start_time": "2019-07-03T10:49:10.405486Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_pattern_segment(pattern):\n",
    "    return pattern.startswith('?*') and all(a.isalpha() for a in pattern[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:49:21.176798Z",
     "start_time": "2019-07-03T10:49:21.171808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pattern_segment('?*P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:49:31.786355Z",
     "start_time": "2019-07-03T10:49:31.782363Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:49:42.716463Z",
     "start_time": "2019-07-03T10:49:42.705534Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_match(rest, saying):\n",
    "    if not rest or not saying:\n",
    "        return True\n",
    "#     elif not rest: return False\n",
    "#     elif not saying: return False\n",
    "    elif not all(s.isalpha() for s in rest[0]): # 如果当前 pattern 第一个是 variable 或者 pattern_segment，则后面的匹配可交给下一次继续进行\n",
    "        return True\n",
    "    elif rest[0] != saying[0]:\n",
    "        return False\n",
    "    else:\n",
    "        return is_match(rest[1:], saying[1:])\n",
    "\n",
    "def segment_match(pattern, saying):\n",
    "    seg_pat, rest = pattern[0], pattern[1:]\n",
    "    seg_pat = seg_pat.replace('?*', '?')\n",
    "    \n",
    "    if not rest: return (seg_pat, saying), len(saying)\n",
    "    \n",
    "    for i, token in enumerate(saying):\n",
    "        # 扩增到直至后面的可匹配\n",
    "        if rest[0] == token and is_match(rest[1:], saying[i+1:]):\n",
    "#             print(token, seg_pat)\n",
    "            return (seg_pat, saying[:i]), i\n",
    "    return (seg_pat, saying), len(saying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:50:29.178887Z",
     "start_time": "2019-07-03T10:50:29.173901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('?PL', ['My', 'dog']), 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_match('?*PL are good'.split(), 'My dog are good too'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:50:40.445012Z",
     "start_time": "2019-07-03T10:50:40.438993Z"
    }
   },
   "outputs": [],
   "source": [
    "fail = [True, None]\n",
    "\n",
    "def pat_match_with_seg(pattern, saying):\n",
    "    # 修改了此处，阻止\"?*X hello ?*Y\"和\"Hi, how do you do\"的匹配，即匹配不允许saying或pattern有剩余，有剩余即为不能匹配\n",
    "    if not pattern and not saying: return []\n",
    "    elif not pattern: return fail\n",
    "    elif not saying and all(s.isalpha() for s in pattern[0]): return fail\n",
    "    pat = pattern[0]\n",
    "    if is_variable(pat):\n",
    "        return [(pat, saying[0])] + pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    elif is_pattern_segment(pat):\n",
    "        match, index = segment_match(pattern, saying)\n",
    "        return [match] + pat_match_with_seg(pattern[1:], saying[index:])\n",
    "    elif pat == saying[0]:\n",
    "        return pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    else:\n",
    "        return fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:50:51.331567Z",
     "start_time": "2019-07-03T10:50:51.325584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('?P', ['My', 'dog', 'and', 'my', 'cat']), 5)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_match('?*P is very good'.split(), \"My dog and my cat is very good is very good\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:51:02.041913Z",
     "start_time": "2019-07-03T10:51:02.036926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('hello', ['hello']), 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_match('hello world boring'.split(), \"hello world\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:51:12.740881Z",
     "start_time": "2019-07-03T10:51:12.734894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?P', ['My', 'dog']), ('?X', ['my', 'cat', 'is', 'very', 'cute'])]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match_with_seg('?*P is very good and ?*X'.split(), \"My dog is very good and my cat is very cute\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:51:40.333512Z",
     "start_time": "2019-07-03T10:51:40.327496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?X', ['an', 'iphone'])]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match_with_seg('I need ?*X'.split(), 'I need an iphone'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:51:51.171476Z",
     "start_time": "2019-07-03T10:51:51.166489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why', 'do', 'you', 'neeed', ['an', 'iPhone']]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute(\"Why do you neeed ?X\".split(), pat_to_dict(pat_match_with_seg('I need ?*X'.split(), \n",
    "                  \"I need an iPhone\".split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:52:02.050616Z",
     "start_time": "2019-07-03T10:52:02.046626Z"
    }
   },
   "outputs": [],
   "source": [
    "def pat_to_dict(patterns):\n",
    "    return {k: ' '.join(v) if isinstance(v, list) else v for k, v in patterns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:52:12.782058Z",
     "start_time": "2019-07-03T10:52:12.776063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why', 'do', 'you', 'neeed', 'an iPhone']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute(\"Why do you neeed ?X\".split(), pat_to_dict(pat_match_with_seg('I need ?*X'.split(), \n",
    "                  \"I need an iPhone\".split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:52:23.683065Z",
     "start_time": "2019-07-03T10:52:23.677082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?X', ['Hi,', 'how', 'do', 'you', 'do']), True, None]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match_with_seg(\"?*X hello ?*Y\".split(), \"Hi, how do you do\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:52:34.398015Z",
     "start_time": "2019-07-03T10:52:34.393969Z"
    }
   },
   "outputs": [],
   "source": [
    "rules = {\n",
    "    \"?*X hello ?*Y\": [\"Hi, how do you do?\"],\n",
    "    \"I was ?*X\": [\"Were you really ?X ?\", \"I already knew you were ?X .\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 问题1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:53:24.341883Z",
     "start_time": "2019-07-03T10:53:24.335939Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_response(saying, response_rules):\n",
    "    for q, a in response_rules.items():\n",
    "        match = pat_match_with_seg(q.split(), saying.split())\n",
    "        if match[-1] != None:\n",
    "            print(match)\n",
    "            resp = np.random.choice(a)\n",
    "            return ' '.join(substitute(resp.split(), pat_to_dict(match)))\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:53:35.139508Z",
     "start_time": "2019-07-03T10:53:35.134487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('?X', ['xhp'])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Were you really xhp ?'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('I was xhp', rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:53:46.086245Z",
     "start_time": "2019-07-03T10:53:46.081330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('?X', []), ('?Y', [])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi, how do you do?'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('hello', rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 问题2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:54:05.719967Z",
     "start_time": "2019-07-03T10:54:05.712980Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_chinese(sentence):\n",
    "    res = []\n",
    "    is_pattern = False\n",
    "    j = 0\n",
    "    for i in range(len(sentence)):\n",
    "        if not is_pattern and ord(sentence[i]) < 128:\n",
    "            tmp = sentence[j:i]\n",
    "            if tmp: res.append(tmp)\n",
    "            j = i\n",
    "            is_pattern = True\n",
    "        if is_pattern and ord(sentence[i]) >= 128:\n",
    "            tmp = sentence[j:i]\n",
    "            if tmp: res.append(tmp)\n",
    "            j = i\n",
    "            is_pattern = False\n",
    "    res.append(sentence[j:])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:54:16.544355Z",
     "start_time": "2019-07-03T10:54:16.538370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?*x', '我想要', '?*y']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_chinese('?*x我想要?*y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:54:48.831485Z",
     "start_time": "2019-07-03T10:54:48.826498Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut_chinese(sentence):\n",
    "    tokens = list(jieba.cut(sentence))\n",
    "    length = len(tokens)\n",
    "    i, j, res = 0, 0, []\n",
    "    while i < length:\n",
    "        if len(tokens[i]) > 1 or ord(tokens[i]) >= 128:\n",
    "            if i > j: \n",
    "                res.append(''.join(tokens[j:i]))\n",
    "                j = i\n",
    "            res.append(tokens[i])\n",
    "            j += 1\n",
    "        i += 1\n",
    "    if i > j: res.append(''.join(tokens[j:i]))\n",
    "    return res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:54:59.717282Z",
     "start_time": "2019-07-03T10:54:59.712295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?*x', '我', '想要', '?*y']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_chinese('?*x我想要?*y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:56:12.278038Z",
     "start_time": "2019-07-03T10:56:12.273019Z"
    }
   },
   "outputs": [],
   "source": [
    "def pat_to_dict(patterns):\n",
    "    return {k: ''.join(v) if isinstance(v, list) else v for k, v in patterns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:56:23.074112Z",
     "start_time": "2019-07-03T10:56:23.068128Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ch_response(saying, response_rules):\n",
    "    for q, a in response_rules.items():\n",
    "        match = pat_match_with_seg(cut_chinese(q), cut_chinese(saying))\n",
    "        print(match)\n",
    "        if match[-1] != None:\n",
    "            resp = np.random.choice(a)\n",
    "            return ''.join(substitute(cut_chinese(resp), pat_to_dict(match)))\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:56:33.679182Z",
     "start_time": "2019-07-03T10:56:33.674167Z"
    }
   },
   "outputs": [],
   "source": [
    "chinese_rules = {\n",
    "    '?*x我想要?*y': ['?x想问你，你觉得?y有什么意义呢?', '为什么你想?y', '?x觉得... 你可以想想你很快就可以有?y了', '你看?x像?y不', '我看你就像?y'],\n",
    "    '?*x喜欢?*y': ['喜欢?y的哪里？', '?y有什么好的呢？', '你想和?y在一起吗？'],\n",
    "    '?*x讨厌?*y': ['?y怎么会那么讨厌呢?', '讨厌?y的哪里？', '?y有什么不好呢？', '你不想要?y吗？']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:56:46.816161Z",
     "start_time": "2019-07-03T10:56:46.810215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('?x', ['我', '喜欢', '毕', '行风']), True, None]\n",
      "[('?x', ['我']), ('?y', ['毕', '行风'])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'毕行风有什么好的呢？'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ch_response('我喜欢毕行风', chinese_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:56:57.602531Z",
     "start_time": "2019-07-03T10:56:57.597510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('?x', []), ('?y', ['一杯', '奶茶'])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'想问你，你觉得一杯奶茶有什么意义呢?'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ch_response('我想要一杯奶茶', chinese_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 问题3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T06:05:15.851283Z",
     "start_time": "2019-07-03T06:05:12.980587Z"
    }
   },
   "source": [
    "通过修改程序实现一个可以多轮对话的机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:58:07.876827Z",
     "start_time": "2019-07-03T10:58:07.869811Z"
    }
   },
   "outputs": [],
   "source": [
    "def mul_rounds_dialogue(response_rules):\n",
    "    while True:\n",
    "        saying = input('you: ')\n",
    "        if saying in ['q', 'exit']: break\n",
    "        for q, a in response_rules.items():\n",
    "            match = pat_match_with_seg(cut_chinese(q), cut_chinese(saying))\n",
    "            if match[-1] != None:\n",
    "                resp = np.random.choice(a)\n",
    "                resp = ''.join(substitute(cut_chinese(resp), pat_to_dict(match)))\n",
    "                print('bot: {}'.format(resp))\n",
    "                break\n",
    "        else:\n",
    "            print('bot: 我词穷了 :-(')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T11:00:06.570214Z",
     "start_time": "2019-07-03T11:00:06.565229Z"
    }
   },
   "outputs": [],
   "source": [
    "dialogue_rules = {\n",
    "    '?*x我想要?*y': ['?x想问你，你觉得?y有什么意义呢?', '为什么你想要?y', '?x觉得... 你可以想想你很快就可以有?y了', '你看?x像?y不', '我看你就像?y'],\n",
    "    '?*y很好玩啊': ['哪里好玩了'],\n",
    "    '?*y很好啊': ['好在哪啊'],\n",
    "    '?*y很有用啊': ['可以用在哪啊，比如...'],\n",
    "    '?*x一点都不像': ['你眼瞎啊', '好吧'],\n",
    "    '?*x哪都好啊': ['那你说说呗😏', '列举一下啊'],\n",
    "    '?*优点多着呢': ['那你说说呗', '列举一下啊'],\n",
    "    '?*x想啊?*y': ['祝你好运，哈哈哈'],\n",
    "    '?*x当然?*y': ['祝你好运，哈哈哈，😄'],\n",
    "    '?*x哪都喜欢': ['服了你了。。。'],\n",
    "    '?*x喜欢?*y': ['喜欢?y的哪里？', '?y有什么好的呢？', '你想和?y在一起吗？'],\n",
    "    '?*x讨厌?*y': ['?y怎么会那么讨厌呢?', '讨厌?y的哪里？', '?y有什么不好呢？', '你不想要?y吗？']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T11:01:17.144846Z",
     "start_time": "2019-07-03T11:00:17.345111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you: 我喜欢毕行风\n",
      "bot: 毕行风有什么好的呢？\n",
      "you: 哪都好啊\n",
      "bot: 那你说说呗😏\n",
      "you: 好看啊、性格又好、又努利\n",
      "bot: 我词穷了 :-(\n",
      "you: 哈哈哈哈\n",
      "bot: 我词穷了 :-(\n",
      "you: q\n"
     ]
    }
   ],
   "source": [
    "mul_rounds_dialogue(dialogue_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 问题4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 这样的程序有什么优点？有什么缺点？你有什么可以改进的方法吗？<br>\n",
    "Ans: <br>\n",
    "    * 优点：不需要经过长时间的训练就可以得到一个简易的对话模型，不需要深厚的专业知识就可以写出各种各样的基于匹配的对话程序\n",
    "    * 缺点： 无法进行持续对话，回答模式过于单一需要人工事先定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 什么是数据驱动？数据驱动在这个程序里如何体现？<br>\n",
    "Ans: <br>\n",
    "    * 我理解的数据驱动就是不挖掘出数据中潜藏的规律和模式，以此来改善我们通过程序获得的结果\n",
    "    * 在这个程序中如果我们定义足够多的样板模式，并对每一种样本模式尽可能详尽的列举可能的回答，那么我们也可以获得非常好的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 数据驱动与 AI 的关系是什么？<br>\n",
    "Ans: 数据可以说是 AI 的基本资料，以上实现的程序也需要我们事先定义好的规则、模式这些数据，然后根据模式通过程序实现匹配实现一个简易的对话机器人，；而现在的大部分 AI 程序则实现了自主探索数据中潜藏的规律，并不需要人工发现，这就对数据量提出了更大的要求，足够多的数据才具有统计意义"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
